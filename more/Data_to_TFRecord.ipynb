{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "60fc8cfc-ff46-4485-9a02-42a5718cf4dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import glob\n",
    "from PIL import Image\n",
    "from tqdm.notebook import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ed728748-be19-41d9-8e1b-61334ccb6159",
   "metadata": {},
   "outputs": [],
   "source": [
    "# IMG_DIR = '/data/images' # a folder of .jpegs\n",
    "# ANN_DIR = '/data/annotations' # folder of annotations\n",
    "\n",
    "ANN_DIR = \"/Users/codyfalkosky/Documents/hidden_desktop/PORTFOLIO_PROJ/working/YOLOv2/steps/data/annotations\"\n",
    "IMG_DIR = \"/Users/codyfalkosky/Documents/hidden_desktop/PORTFOLIO_PROJ/working/YOLOv2/steps/data/images\"\n",
    "\n",
    "image_paths = glob.glob(IMG_DIR+'/*.jpg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a2652440-75d6-49f3-ad7f-c6d8576a66be",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_filename(path):\n",
    "    'extracts filename from path'\n",
    "    root, file_name = path.rsplit('/', 1)\n",
    "    file_name, ext  = file_name.rsplit('.', 1)\n",
    "    return file_name\n",
    "\n",
    "def load_annotation(file_name):\n",
    "    'load annotation associated with image based off filename'\n",
    "    path = ANN_DIR + '/' + file_name + '.txt'\n",
    "    \n",
    "    with open(path, 'r') as file:\n",
    "        annotation = file.read()\n",
    "\n",
    "    return annotation\n",
    "\n",
    "def load_image(path):\n",
    "    'load image from path'\n",
    "    image = Image.open(path)\n",
    "    image = np.array(image)\n",
    "    image = image.tolist()\n",
    "    return image \n",
    "\n",
    "def annotation_to_labels_boxes(annotation):\n",
    "    'parse annotations to labels and boxes'\n",
    "    annotation = annotation.split()\n",
    "    annotation = np.array(annotation, dtype=np.float32)\n",
    "    annotation = np.reshape(annotation, (-1, 5))\n",
    "\n",
    "    labels = annotation[:, 0:1]\n",
    "    boxes  = annotation[:, 1:5]\n",
    "\n",
    "    labels = labels.tolist()\n",
    "    boxes = boxes.tolist()\n",
    "    return labels, boxes\n",
    "\n",
    "def image_labels_boxes(image_path):\n",
    "    '''\n",
    "    returns image, labels and boxes from an image path\n",
    "    above functions combined into a single call\n",
    "    '''\n",
    "    image = load_image(image_path)\n",
    "    labels, boxes = annotation_to_labels_boxes(load_annotation(extract_filename(image_path)))\n",
    "    return image, labels, boxes    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "97cedc6c-22ae-4cb5-a872-26e7ddd82335",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _bytes_feature(value):\n",
    "  \"\"\"Returns a bytes_list from a string / byte.\"\"\"\n",
    "  if isinstance(value, type(tf.constant(0))):\n",
    "    value = value.numpy() # BytesList won't unpack a string from an EagerTensor.\n",
    "  return tf.train.Feature(bytes_list=tf.train.BytesList(value=[value]))\n",
    "\n",
    "def _float_feature(value):\n",
    "    \"\"\"Returns a float_list from a float / double.\"\"\"\n",
    "    return tf.train.Feature(float_list=tf.train.FloatList(value=value.reshape(-1)))\n",
    "\n",
    "\n",
    "def serialize_example(image, labels, boxes):\n",
    "    \"\"\"Reads a single (image, labels, boxes) example and serializes for storage as TFRecord\"\"\"\n",
    "\n",
    "    feature = {\n",
    "        'image'  : _bytes_feature(tf.io.encode_jpeg(image)),\n",
    "        'labels' : _float_feature(labels),\n",
    "        'boxes'  : _float_feature(boxes)\n",
    "    }\n",
    "    example_proto = tf.train.Example(features=tf.train.Features(feature=feature))\n",
    "    return example_proto.SerializeToString()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8b5a228f-e2aa-4e5b-aa58-ccf7017cb2bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# SHARD DATA\n",
    "REC_DIR = '/data/records/'\n",
    "full_shard = 256\n",
    "example_no = 0\n",
    "shard_no   = 0\n",
    "\n",
    "print('Sharding: Data')\n",
    "for image_path in tqdm(image_paths, total=len(image_paths)):\n",
    "    if example_no % full_shard == 0:\n",
    "        if example_no != 0:\n",
    "            shard_no += 1\n",
    "            writer.close()            \n",
    "        shard_filename = REC_DIR + f'hollywood_traffic_shard_{shard_no}.tfrecords'\n",
    "        writer = tf.io.TFRecordWriter(shard_filename)\n",
    "    \n",
    "    serialized_example = serialize_example(*image_labels_boxes(image_path))\n",
    "    writer.write(serialized_example)\n",
    "    example_no += 1\n",
    "\n",
    "writer.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd7a4f18-c17f-42b0-bbcf-94920da10b3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# push to hf hub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9a947587-eff6-4dce-b48c-69f255de617f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from datasets import Dataset, load_dataset, load_from_disk\n",
    "\n",
    "# DATASET = []\n",
    "\n",
    "# for img_path in tqdm(image_paths):\n",
    "#     image, labels, boxes = image_labels_boxes(img_path)\n",
    "#     DATASET.append({'image':image, 'labels':labels, 'boxes':boxes})\n",
    "\n",
    "# dataset = Dataset.from_list(DATASET)\n",
    "# data.push_to_hub('codyfalkosky/hollywood_traffic', token='')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
